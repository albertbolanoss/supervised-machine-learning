{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98ee4977",
   "metadata": {},
   "source": [
    "# Decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a21b879",
   "metadata": {},
   "source": [
    "- Decision trees are powerful classification and regression models\n",
    "- Decision trees are trained with labeled data\n",
    "- App-recommendation, Health care\n",
    "\n",
    "\n",
    "Decision tree: A machine learning model  based on yes-or-no questions and represented by a binary tree.  The tree has a root node, decision node, left node and branches.\n",
    "\n",
    "root node: the topmost node of the tree.\n",
    "\n",
    "Decision node: Each yes-or-no question in our model\n",
    "\n",
    "Leaf node: A node that has no branch emaning from it.\n",
    "\n",
    "Depth: the number of levels in the decision tree.\n",
    "\n",
    "\n",
    "1. Figure out which of the data is the most useful to decide which app to recommend.\n",
    "1. This feature splits the data into two smaller datasets.\n",
    "1. Repeat processes 1 and 2 for each of the two smaller datasets.\n",
    "\n",
    "In other words, what we do is decide which of the two features (platform or age) is more successful at determining which app the users will download and pick this one as our root of the decision tree.\n",
    "\n",
    "The first step to build our model is to figure out the most useful feature: in other words, the most useful question to ask. First, let’s simplify our data a little bit. Let’s call everyone under 20 years old “Young” and everyone 20 or older “Adult”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ebcfcdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Platform  Age              App Age_Group\n",
      "0   iPhone   15       Atom Count     Young\n",
      "1   iPhone   25  Check Mate Mate     Adult\n",
      "2  Android   32   Beehive Finder     Adult\n",
      "3   iPhone   35  Check Mate Mate     Adult\n",
      "4  Android   12       Atom Count     Young\n",
      "5  Android   14       Atom Count     Young\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Dataset original\n",
    "data = {\n",
    "    'Platform': ['iPhone', 'iPhone', 'Android', 'iPhone', 'Android', 'Android'],\n",
    "    'Age': [15, 25, 32, 35, 12, 14],\n",
    "    'App': ['Atom Count', 'Check Mate Mate', 'Beehive Finder', 'Check Mate Mate', 'Atom Count', 'Atom Count']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Agregar columna 'Age Group'\n",
    "df['Age_Group'] = df['Age'].apply(lambda age: 'Young' if age < 20 else 'Adult')\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c7b7ce",
   "metadata": {},
   "source": [
    "a. Evaluete first question (by platform):\n",
    "\n",
    "                                            Split by platform\n",
    "                                           /                 \\\n",
    "                                          iPhone             Android\n",
    "                                          /                   \\\n",
    "                                Atom Chess Chess             Atom Atom Bee\n",
    "\n",
    "\n",
    "b. Evaluete first question (by platform):\n",
    "\n",
    "                                               Split by age\n",
    "                                           /                 \\\n",
    "                                          Young             Adult\n",
    "                                          /                   \\\n",
    "                                Atom Atom Atom             Chess Chess Bee\n",
    "\n",
    "\n",
    "We need to validate which is better questions to split the data.\n",
    "\n",
    "\n",
    "                            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd205a6",
   "metadata": {},
   "source": [
    "### Accurracy:  \n",
    "\n",
    "Accuracy is the fraction of correctly classified data points over the total number of data points.\n",
    "\n",
    "**Classifier 1**: What platform do you use?\n",
    "\n",
    "\n",
    "- If the answer is “iPhone,” then we notice that of the iPhone users, the majority downloaded Check Mate Mate. Therefore, we recommend Check Mate Mate to all the iPhone users. We are correct two times out of three\n",
    "- If the answer is “Android,” then we notice that of the Android users, the majority downloaded Atom Count, so that is the one we recommend to all the Android users. We are correct two times out of three.\n",
    "\n",
    "\n",
    "**Classifier 2**: What is your age?\n",
    "\n",
    "- If the answer is “young,” then we notice that all the young people downloaded Atom Count, so that is the recommendation we make. We are correct three times out of three.\n",
    "- If the answer is “adult,” then we notice that of the adults, the majority downloaded Check Mate Mate, so we recommend that one. We are correct two times out of three.\n",
    "\n",
    "Notice that classifier 1 is correct four times out of six, and classifier 2 is correct five times out of six. Therefore, for this dataset, classifier 2 is better. \n",
    "\n",
    "classifier 1: 4 / 6 = 0.666\n",
    "\n",
    "classifier 2: 5 / 6 = 0.833\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd606637",
   "metadata": {},
   "source": [
    "### Gini impurity index: How diverse is my dataset?\n",
    "\n",
    "Measure of diversity of the dataset.\n",
    "\n",
    "- if all elements are similar so the gini index is low\n",
    "- if the elements are diferent so the gini index is is large\n",
    "\n",
    "For clarity, consider the following two sets of 10 colored balls (where any two balls of the same color are indistinguishable):\n",
    "\n",
    "Set 1: eight red balls, two blue balls\n",
    "Set 2: four red balls, three blue balls, two yellow balls, one green ball\n",
    "Set 1 looks more pure than set 2, because set 1 contains mostly red balls and a couple of blue ones, whereas set 2 has many different colors. Next, we devise a measure of impurity that assigns a low value to set 1 and a high value to set 2. This measure of impurity relies on probability. Consider the following question:\n",
    "\n",
    "- Set 1: eight red balls, two blue balls\n",
    "- Set 2: four red balls, three blue balls, two yellow balls, one green ball\n",
    "\n",
    "Set 1 looks more pure than set 2, because set 1 contains mostly red balls and a couple of blue ones, whereas set 2 has many different colors\n",
    "\n",
    "If we pick two random elements of the set, what is the probability that they have a different color? The two elements don’t need to be distinct; we are allowed to pick the same element twice.\n",
    "\n",
    "Note: this is Mutually exclusive events (cannot occur simultaneously,are independent events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c34d96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_once_blue = 8 / 10\n",
    "p_once_red = 2 / 10\n",
    "\n",
    "p_twice_blue = p_once_blue ** 2\n",
    "p_twice_red = p_once_red ** 2\n",
    "\n",
    "\n",
    "p_diff_color = 1 - p_twice_blue - p_twice_red\n",
    "\n",
    "# gini impurity index In a set with m elements and n classes,\n",
    "#  with ai elements belonging to the i-th class, the Gini impurity index is\n",
    "# Gini = 1 – p1⌃2 – p2⌃2 – … – pn⌃2,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e92e56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini Classifier1 (Platform): 0.4444444444444445\n",
      "Gini Classifier2 (Age): 0.2222222222222222\n",
      "We conclude that the second split is better, because it has a lower average Gini index.\n"
     ]
    }
   ],
   "source": [
    "# Gini index to decide which two way to split the data (age or platform)\n",
    "\n",
    "# Classifier 1: \n",
    "# \n",
    "# Left leaf: {A, C, C}\n",
    "# Right leaf: {A, A, B}\n",
    "\n",
    "\n",
    "# Classifier 2: \n",
    "# \n",
    "# Left leaf: {A, A, A}\n",
    "# Right leaf: {B, C, C}\n",
    "\n",
    "# Checking Left branch of the classifier 1 and classifier 2\n",
    "# Gini = 1 – p1⌃2 – p2⌃2 – … – pn⌃2,\n",
    "left_gini_classifier1 = 1 - (2 / 3) ** 2 - (1 / 3) ** 2 \n",
    "right_gini_classifier1 = 1 - (2 / 3) ** 2 - (1 / 3) ** 2 \n",
    "avg_gini_classifier1 = 1 / 2 * (left_gini_classifier1 + right_gini_classifier1)\n",
    "\n",
    "left_gini_classifier2 = 1 - (3 / 3) ** 2\n",
    "right_gini_classifier2 = 1 - (1 / 3) ** 2 - (2 / 3) ** 2\n",
    "avg_gini_classifier2 = 1 / 2 * (left_gini_classifier2 + right_gini_classifier2)\n",
    "\n",
    "print(f\"Gini Classifier1 (Platform): {avg_gini_classifier1}\")\n",
    "print(f\"Gini Classifier2 (Age): {avg_gini_classifier2}\")\n",
    "print(\"We conclude that the second split is better, because it has a lower average Gini index.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa8ed77",
   "metadata": {},
   "source": [
    "\n",
    "### Entropy: Another measure of diversity with strong applications in information theory\n",
    "\n",
    "Consider the same two sets of colored balls as in the previous section, but think of the colors as an ordered set.\n",
    "\n",
    "- Set 1: {red, red, red, red, red, red, red, red, blue, blue} (eight red balls, two blue balls)\n",
    "- Set 2: {red, red, red, red, blue, blue, blue, yellow, yellow, green} (four red balls, three blue balls, two yellow balls, one green ball)\n",
    "\n",
    "### Calculate the probability of get the initial order\n",
    "\n",
    "**Set1:**\n",
    "\n",
    "P(r,r,r,r,r,r,r,r,b,b) = 8/10 x 8/10 x 8/10 x 8/10 x 8/10 x 8/10 x 8/10 x 8/10 x 2/10 x 2/10\n",
    "\n",
    "P(r,r,r,r,r,r,r,r,b,b) = (8/10)⌃8 x (2/10)⌃2\n",
    "\n",
    "P(r,r,r,r,r,r,r,r,b,b) = 0.006708864\n",
    "\n",
    "**Set2:**\n",
    "\n",
    "P(r,r,r,r,b,b,b,y,y,g) =  4/10 x 4/10 x 4/10 x 4/10 x 3/10 * 3/10 x 3/10 x 2/10 x 2/10 x 1 / 10\n",
    "\n",
    "P(r,r,r,r,b,b,b,y,y,g) =  (4/10)⌃4 x (3/10)⌃4 x  (2/10)⌃4 x (1/10)⌃1  \n",
    "\n",
    "P(r,r,r,r,r,r,r,r,b,b) = 0.0000027648\n",
    "\n",
    "The Set1 is more likehook to get the initial order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda23b1e",
   "metadata": {},
   "source": [
    "Why we need Entropy\n",
    "\n",
    "- Because the probabibilities returns very small decimal and these are cost to process  by the computers\n",
    "\n",
    "\n",
    "Note: How help log to reduce the complexity : For instance, 0.000000000000001 is equal to 10–15\n",
    "\n",
    "log(ab) = log(a) + log(b)\n",
    "\n",
    "log(ac) = c log(a)\n",
    "\n",
    "Entropy = -1 / n Log base 2 [p1⌃x . p2⌃y . ....]\n",
    "\n",
    "Entropy = -x /n Log base 2 p1 - y/n log base 2 p2\n",
    "\n",
    "**Set 1**:\n",
    "\n",
    "Entropy = - 1 / n Log base 2 [p1⌃x . p2⌃y . ....]\n",
    "\n",
    "Entropy = -1 / 10 log base 2 [(8/10)⌃8 x (2/10)⌃2]\n",
    "\n",
    "Entropy = -8 / 10 log base 2 (8/10) - 2 / 10 log base 2 2/10 \n",
    "\n",
    "Entropy = 0.722\n",
    "\n",
    "**Set 2**:\n",
    "\n",
    "Entropy = - 1 / n Log base 2 [p1⌃x . p2⌃y . ....]\n",
    "\n",
    "Entropy = -1 / 10 log base 2 [(4/10)⌃4 x (3/10)⌃3 x  (2/10)⌃2 x  (1/10)⌃1]\n",
    "\n",
    "Entropy = -4 / 10 log base 2 (4/10) - 3 / 10 log base 2 3/10 - 2 / 10 log base 2 2/10 - 1 / 10 log base 2 1/10 \n",
    "\n",
    "Entropy = 1.846\n",
    "\n",
    "**Notice that the entropy of set 2 is larger than the entropy of set 1, which implies that set 2 is more diverse than set 1. The following is the formal definition of entropy**:\n",
    "\n",
    "**Entropy = -p1 x log base 2 (p1) - p2 x log base 2 (p2) x .... pn x log base 2 (pn)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5fc074dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy C1 0.9182958340544896\n",
      "Entropy C2 0.4591479170272448\n",
      "C2 has less diverse the data so this is better question for us tree node\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# Entropy to decide which two way to split the data (age or platform)\n",
    "\n",
    "# Classifier 1 (Platform): \n",
    "# \n",
    "# Left leaf: {A, C, C}\n",
    "# Right leaf: {A, A, B}\n",
    "\n",
    "c1_p1_left = 2/3\n",
    "c1_p2_left = 1/3\n",
    "c1_p1_right = 2/3\n",
    "c1_p2_right = 1/3\n",
    "\n",
    "entropy_c1_left = -c1_p1_left *  math.log2(c1_p1_left) - c1_p2_left *  math.log2(c1_p2_left)\n",
    "entropy_c1_right = -c1_p1_right *  math.log2(c1_p1_right) - c1_p2_right *  math.log2(c1_p2_right)\n",
    "entropy_c1 = 1 / 2 * (entropy_c1_left + entropy_c1_right)\n",
    "\n",
    "# Classifier 2 (Age): \n",
    "# \n",
    "# Left leaf: {A, A, A}\n",
    "# Right leaf: {B, C, C}\n",
    "\n",
    "\n",
    "c2_p1_left = 3/3\n",
    "c2_p1_right = 2/3\n",
    "c2_p2_right = 1/3\n",
    "\n",
    "entropy_c2_left = -c2_p1_left *  math.log2(c2_p1_left)\n",
    "entropy_c2_right = -c2_p1_right *  math.log2(c2_p1_right) - c2_p2_right *  math.log2(c2_p2_right)\n",
    "entropy_c2 = 1 / 2 * (entropy_c2_left + entropy_c2_right)\n",
    "\n",
    "print(f\"Entropy C1 {entropy_c1}\")\n",
    "print(f\"Entropy C2 {entropy_c2}\")\n",
    "print(\"C2 has less diverse the data so this is better question for us tree node\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656f4082",
   "metadata": {},
   "source": [
    "### Weighted average\n",
    "\n",
    "El promedio ponderado (o media ponderada) es una forma de calcular un promedio en la que no todos los valores tienen la misma importancia o peso. En lugar de simplemente sumar los valores y dividir entre la cantidad (como en el promedio simple), en el promedio ponderado cada valor se multiplica por un peso que refleja su relevancia, y luego se divide entre la suma total de los pesos.\n",
    "\n",
    "Imagine that you have a dataset with eight data points (which when training the decision tree, we also refer to as samples), and you split it into two datasets of sizes six and two. As you may imagine, the larger dataset should count for more in the calculations of Gini impurity index or entropy. Therefore, instead of considering the average, we consider the weighted average, where at each leaf, we assign the proportion of points corresponding to that leaf. Thus, in this case, we would weigh the first Gini impurity index (or entropy) by 6/8, and the second one by 2/8.\n",
    "\n",
    "weight_avg_gini = 0.4444 * 6 / 8  + 0 * 2 / 8 = 0.3333\n",
    "weight_avg_entropy = 0.918 * 6 /8 + 0 * 2 / 8 = 0.689"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db249b7",
   "metadata": {},
   "source": [
    "### Second step to build the model: Iterating\n",
    "\n",
    "1. Find the Best Split. Use metrics (like Gini, entropy, or accuracy) to choose the best feature to split the dataset.\n",
    "1. Split the Dataset. Divide the dataset into subsets based on that feature.\n",
    "1. Check for Purity\n",
    "    If all labels in a subset are the same → make it a leaf node with a final prediction.\n",
    "    If not → go to step 4.\n",
    "1. Repeat the Process. For each non-pure subset:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3473b2",
   "metadata": {},
   "source": [
    "### Last step (when stop and hyperparameters)\n",
    "\n",
    "Since infinite cycles can occur while the tree is being split, we can control it:\n",
    "\n",
    "1. Don’t split a node if the change in accuracy, Gini index, or entropy is below some threshold.\n",
    "1. Don’t split a node if it has less than a certain number of samples.\n",
    "1. Split a node only if both of the resulting leaves contain at least a certain number of samples.\n",
    "1. Stop building the tree after you reach a certain depth.\n",
    "\n",
    "#### Hyperparametres\n",
    "\n",
    "1. The minimum amount of change in accuracy (or Gini index, or entropy)\n",
    "1. The minimum number of samples that a node must have to split it\n",
    "1. The minimum number of samples allowed in a leaf node\n",
    "1. The maximum depth of the tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b289f3b8",
   "metadata": {},
   "source": [
    "### Grid search\n",
    "\n",
    "The way we pick these hyperparameters is either by experience or by running an exhaustive search where we look for different combinations of hyperparameters and choose the one that performs best in our validation set. This process is called grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1067a8",
   "metadata": {},
   "source": [
    "### Splitting the data using non-binary categorical features, such as dog/cat/bird\n",
    "\n",
    " For example, if the input is an animal that could be a dog, a cat, or a bird, then we ask the following questions:\n",
    "\n",
    "- Is the animal a dog?\n",
    "- Is the animal a cat?\n",
    "- Is the animal a bird?\n",
    "\n",
    ". This process of turning a nonbinary categorical feature into several binary features is called **one-hot encoding** \n",
    "\n",
    "Example: \n",
    "    dog:   Cat:     bird\n",
    "      1     0       0 \n",
    "      0     1       0\n",
    "      0     0       1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a26bb19",
   "metadata": {},
   "source": [
    "### Splitting the data using continuous features, such as age\n",
    "\n",
    "Evaluate each posible value as yes/no question\n",
    "\n",
    "| Platform | Age | App             |\n",
    "|----------|-----|------------------|\n",
    "| iPhone   | 15  | Atom Count       |\n",
    "| iPhone   | 25  | Check Mate Mate  |\n",
    "| Android  | 32  | Beehive Finder   |\n",
    "| iPhone   | 35  | Check Mate Mate  |\n",
    "| Android  | 12  | Atom Count       |\n",
    "| Android  | 14  | Atom Count       |\n",
    "\n",
    "Is the user younger than 12?\n",
    "Is the user younger than 14?\n",
    "Is the user younger than 15?\n",
    "Is the user younger than 15?\n",
    "Is the user younger than 25?\n",
    "Is the user younger than 32?\n",
    "Is the user younger than 35?\n",
    "\n",
    "| Question                          | First set (yes)            | Second set (no)       | Labels (yes), Labels (no)         | Weighted accuracy | Weighted Gini impurity index | Weighted entropy |\n",
    "|----------------------------------|-----------------------------|------------------------|------------------------------------|-------------------|-------------------------------|------------------|\n",
    "| Is the user younger than 7?      | empty                      | 12, 14, 15, 25, 32, 35 | {}, {A,A,A,C,B,C}                  | 3/6               | 0.611                         | 1.45             |\n",
    "| Is the user younger than 13?     | 12                         | 14, 15, 25, 32, 35     | {A}, {A,A,C,B,C}                   | 3/6               | 0.533                         | 1.26             |\n",
    "| Is the user younger than 20?     | 12, 14, 15                 | 25, 32, 35             | {A,A,A}, {C,B,C}                   | 5/6               | 0.222                         | 0.45             |\n",
    "| Is the user younger than 28.5?   | 12, 14, 15, 25             | 32, 35                 | {A,A,A,C}, {B,C}                   | 4/6               | 0.416                         | 0.87             |\n",
    "| Is the user younger than 33.5?   | 12, 14, 15, 25, 32         | 35                     | {A,A,A,C,B}, {C}                   | 4/6               | 0.467                         | 1.14             |\n",
    "| Is the user younger than 100?    | 12, 14, 15, 25, 32, 35     | empty                  | {A,A,A,C,B,C}, {}                  | 3/6               | 0.611                         | 1.45             |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "supervised-machine-learning-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
