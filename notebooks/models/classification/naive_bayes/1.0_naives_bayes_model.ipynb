{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da9bc69b",
   "metadata": {},
   "source": [
    "# Naives Bayes Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9b4ce4",
   "metadata": {},
   "source": [
    "- The naive Bayes model is a purely probabilistic mode. \n",
    "- The main component of the naive Bayes model is Bayes’ theorem.\n",
    "\n",
    "It’s called naive Bayes because to simplify the calculations, we make a slightly naive assumption that is not necessarily true. However, this assumption helps us come up with a good estimate of the probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67530120",
   "metadata": {},
   "source": [
    "📊 Datos del problema.\n",
    "\n",
    "Precisión (sensibilidad y especificidad):\n",
    "\n",
    "99% de los enfermos dan positivo → sensibilidad = 99%\n",
    "\n",
    "99% de los sanos dan negativo → especificidad = 99%\n",
    "\n",
    "Prevalencia de la enfermedad:\n",
    "\n",
    "Solo 1 de cada 10 000 personas tiene la enfermedad → 0.01%\n",
    "\n",
    "📐 Cálculo Bayesiano (aproximado con 1 millón de personas)\n",
    "\n",
    "En un grupo de 1 000 000 de personas:\n",
    "\n",
    "TP = 1 de cada 10 000 → 100 personas\n",
    "\n",
    "TN = 999 900 personas\n",
    "\n",
    "✔️ Prueba en los enfermos reales:\n",
    "\n",
    "99% de 100 enfermos → 99 dan positivo (true positives)\n",
    "\n",
    "❌ Prueba en los sanos:\n",
    "1% de 999,900 sanos → 9999 dan falsos positivos\n",
    "\n",
    "📦 Total de positivos:\n",
    "\n",
    "Verdaderos positivos: 99\n",
    "\n",
    "Falsos positivos: 9999\n",
    "\n",
    "Total positivos: 99 + 9999 = 10 098\n",
    "\n",
    "\n",
    "p = 99 / 99 + 9999 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e5016e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Sick: 100.0 - Global Healthy: 999900.0\n",
      "True Sick: 99.0 - False Healthy: 9999.00000000001\n",
      "Probability of positive: 0.009803921568627442\n"
     ]
    }
   ],
   "source": [
    "p_have_disease = 0.0001\n",
    "p_test_effectiveness = 99/100\n",
    "sample = 1_000_000\n",
    "\n",
    "\n",
    "global_sick = sample * p_have_disease \n",
    "global_healthy = sample * (1 - p_have_disease)\n",
    "\n",
    "true_positive = global_sick * p_test_effectiveness\n",
    "false_negative = global_healthy * (1 - p_test_effectiveness)\n",
    "\n",
    "print(f\"Global Sick: {global_sick} - Global Healthy: {global_healthy}\")\n",
    "print(f\"True Sick: {true_positive} - False Healthy: {false_negative}\")\n",
    "\n",
    "p_positive = true_positive / (true_positive + false_negative)\n",
    "\n",
    "print(f\"Probability of positive: {p_positive}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b468fa2d",
   "metadata": {},
   "source": [
    "Prelude to Bayes’ theorem: The prior, the event, and the posterior\n",
    "\n",
    "**prior** The initial probability\n",
    "\n",
    "**event** Something that occurs, which gives us information\n",
    "\n",
    "**posterior** The final (and more accurate) probability that we calculate using the prior probability and the event\n",
    "\n",
    "An example follows. Imagine that we want to find out the probability that it will rain today. If we don’t know anything, we can come up with only a rough estimate for the probability, which is the prior. If we look around and find out that we are in the Amazon rain forest (the event), then we can come up with a much more exact estimate. In fact, if we are in the Amazon rain forest, it will probably rain today. This new estimate is the posterior.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09640b3e",
   "metadata": {},
   "source": [
    "### Rule of complementary probabilitis\n",
    "\n",
    "P(Ec) = 1 − P(E)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6e9c89",
   "metadata": {},
   "source": [
    "1. First\n",
    "\n",
    "- P(lottery | spam) = 15 = / 20 = 0.75 => the probability that a spam email contains the word lottery.\n",
    "- P(no lottery | spam): = 1 - 0.75 = 0.25 => the probability that a spam email does not contain the word lottery.\n",
    "- P(lottery | ham): 5 / 80 = 0.0625 => the probability that a ham email contains the word lottery.\n",
    "- P(no lottery | ham): 1 - 0.0625 = 0.9375 => the probability that a ham email does not contain\n",
    "\n",
    "![Confusion's Matriz](../../../../images/Emal_spam_ham.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511e4ae5",
   "metadata": {},
   "source": [
    "\n",
    "![Confusion's Matriz](../../../../images/product_rule_probabilities2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ff7785",
   "metadata": {},
   "source": [
    "P(lottery | spam) = 3 / 4 = 0.75\n",
    "\n",
    "P(no lottery | spam) = 1 - P(lottery | spam) = 1 - 0.75 = 0.25\n",
    "\n",
    "P(lottery | ham) = 1 / 16  = 0.0625\n",
    "\n",
    "P(no lottery | ham) = 1 - P(lottery | ham) = 1 - 0.0625 = 0.9375\n",
    "\n",
    "The next thing we do is find the probabilities of two events happening at the same time. More specifically, we want the following four probabilities:\n",
    "\n",
    "- The probability that an email is spam and contains the word lottery\n",
    "- The probability that an email is spam and does not contain the word lottery\n",
    "- The probability that an email is ham and contains the word lottery\n",
    "- The probability that an email is ham and does not contain the word lottery\n",
    "These events are called intersections of events and denoted with the symbol ∩. Thus, we need to find the following probabilities:\n",
    "\n",
    "P('lottery' ∩ spam)  = 3 / 4 * 1 / 5 = 3 /20 = 0.15\n",
    " \n",
    "P(no 'lottery' ∩ spam) = 1 / 4 * 1 / 5 = 1 / 20 = 0.05\n",
    "\n",
    "P('lottery' ∩ ham) = 1 / 16 * 4 / 5 =  1 / 20 = 0.05\n",
    "\n",
    "P(no 'lottery' ∩ ham) = 15 / 16 * 4 / 5 = 15 / 20 = 0.75\n",
    "\n",
    "![Confusion's Matriz](../../../../images/product_rule_probabilities.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9fcbac",
   "metadata": {},
   "source": [
    " \n",
    "To convert to  probabilities thas add to 1:\n",
    "\n",
    " P(lottery ∩ spam) = 3 / 20 / (3 / 20 + 1 / 20) = 3 / 4\n",
    "\n",
    " P(lottery ∩ ham) = 1 / 20 / (3 / 20 + 1 / 20) = 1 / 4 \n",
    "\n",
    " ![Confusion's Matriz](../../../../images/email-spam_lottery.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b752478",
   "metadata": {},
   "source": [
    "## Formulas 1\n",
    "\n",
    "P(spam | lottery) = P(lottery ∩ spam)  / ( P(lottery ∩ spam) + P(lottery ∩ ham) )\n",
    "\n",
    "P(ham | lottery) = P(lottery ∩ ham)  / ( P(lottery ∩ ham) + P(lottery ∩ spam) )\n",
    "\n",
    "## Formulas 2\n",
    "\n",
    "P(spam | lottery) = P(lottery | spam) * P(spam) / ( P(lottery | spam) * P(spam) + P(lottery | ham) * P(ham) )\n",
    "\n",
    "P(ham | lottery) = P(lottery | ham) * P(ham) / ( P(lottery | ham) * P(ham) + P(lottery | spam) * P(spam) )\n",
    "\n",
    "\n",
    "## Bayes theorem\n",
    "\n",
    "P(E|F) = P(F|E) * P(E) / P(F)\n",
    "\n",
    "Because the event F can be broken down into the two disjoint events F|E and F|Ec, then\n",
    "\n",
    "P(E|F) = P(F|E) * P(E) / ( P(F|E) * P(E) + P(F|Ec) * P(Ec) )\n",
    "\n",
    "\n",
    "P(spam | lottery) = 1 / 5 * 3 /4 / ( 1 / 5 *  3 / 4 + 4 / 5 * 1 / 16) = 3 / 4 = 0.75\n",
    "\n",
    "P(spam | ham) = 4 / 5 * 1 / 16 / ( 4 / 5 * 1 / 16 + 1 / 5 *  3 / 4) = 1 / 4 = 0.25\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fac5103",
   "metadata": {},
   "source": [
    "## Bayes theorem with multiples features\n",
    "\n",
    "\n",
    "\n",
    "P(lottery | spam) = 0.75\n",
    "\n",
    "P(lottery | ham) = 0.25\n",
    "\n",
    "P(sales | spam) =  6 / 20  = 0.3\n",
    "\n",
    "P(sales | ham) = 4 / 80 = 0.05\n",
    "\n",
    "P(lottery, sales | spam) = 0.75 * 0.3 = 0.225\n",
    "\n",
    "P(lottery, sales | ham) = 0.25 * 0.05  = 0.0125\n",
    "\n",
    "\n",
    "**naive assumption The words appearing in an email are completely independent of each other. In other words, the appearance of a particular word in an email in no way affects the appearance of another one.**\n",
    "\n",
    "Most likely, the naive assumption is not true. The appearance of one word can sometimes heavily influence the appearance of another. For example, if an email contains the word salt, then the word pepper is more likely to appear in this email, because many times they go together. This is why our assumption is naive"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
